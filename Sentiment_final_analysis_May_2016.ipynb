{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run /Users/admin/pycommon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Execute SQL to sample posts tagged 'politics', 'life', 'design', 'education' or 'tech', their full text, timestamp, total reading time (ttr), drafting time, reccomends, responses and tags\n",
    "\n",
    "# TABLESAMPLE function should be available in Postgresql 9.5 - go/sql doesn't recognize it, neither does databricks. TABLESAMPLE BERNOULLI (10) REPEATABLE(200) would also be great, tho similarly unavailable. \n",
    "\n",
    "# 236632 total articles across these 5 categories. Random sample of %30 is about 71000. 32472 'Politics' posts, 56002 'Tech, 28601 'Education', 41684 'Design', 78049 'Life'.  Sampling random %30 should be representative for each genre, though not necessarily over time, since we can't sample a given percentage by genre by day. Since bulk (87.4%) of articles seem to be after Aug 1, 2015, query below samples 80000 random articles across all 5 genres from Aug 1 2015 to present date. From 8-1-2015 to 4-2-2016, 206845 total articles across all genres, 29672 'Politics', 46388 'Tech', 25775 'Education', 35694 'Design', 69361 'Life'.  This is a random sample of about 36% of population, n=206845. \n",
    "\n",
    "query = \"\"\"\n",
    "-- Select relevant posts, their text and reading features \n",
    "WITH raw_posts AS (\n",
    "  SELECT\n",
    "    posts.post_id AS ID\n",
    "  , latest_versions.display_title\n",
    "  , TIMESTAMP 'epoch' + posts.first_published_at / 1000 * INTERVAL '1 Second' AS first_published_at\n",
    "  , JSON_EXTRACT_PATH_TEXT(latest_versions.content, 'bodyModel', 'paragraphs') AS paragraphs\n",
    "  FROM posts\n",
    "  -- Full inner join with users, latest_versions and post_features to\n",
    "  -- make sure we only consider posts that have all data that we need\n",
    "  JOIN users ON users.user_id = posts.creator\n",
    "  JOIN latest_versions ON latest_versions.post_id = posts.post_id\n",
    "  WHERE\n",
    "    -- Filter posts that are actually published\n",
    "    posts.first_published_at > 0\n",
    "    AND (posts.visibility = 0 OR posts.visibility = '')\n",
    "    AND posts.deleted_at = 0\n",
    "    AND posts.blacklisted_at = 0\n",
    "    AND users.blacklisted_at = 0\n",
    "    AND latest_versions.is_published\n",
    "    -- Filter posts that are in English\n",
    "    AND posts.detected_language = 'en'\n",
    "    -- Filter posts with tags related to 'politics'\n",
    "    AND posts.post_id IN( \n",
    "      SELECT p2.post_id \n",
    "      FROM posts AS p2 \n",
    "      JOIN tag_post_relations as tog ON p2.post_id = tog.post_id\n",
    "      WHERE tog.tag_slug SIMILAR TO '%politics%|%life%|%design%|%education%|%tech%'\n",
    "      )\n",
    "  -- Remove posts that are responses\n",
    "  AND (posts.in_response_to_post_id = '' OR posts.in_response_to_post_id IS NULL)\n",
    "), \n",
    "\n",
    "-- Generate a series of indices, use LIMIT N to specify the length\n",
    "seq_1_to_N AS (\n",
    "  SELECT ROW_NUMBER() OVER (ORDER BY TRUE) AS i FROM raw_posts\n",
    "  LIMIT 100\n",
    "),\n",
    "-- Explode the paragraphs-array\n",
    "exploded_posts AS (\n",
    "  SELECT\n",
    "    rp.ID AS ID2\n",
    "  , rp.first_published_at\n",
    "  , rp.display_title\n",
    "  , seq.i AS paragraph\n",
    "  , JSON_EXTRACT_PATH_TEXT(JSON_EXTRACT_ARRAY_ELEMENT_TEXT(paragraphs, seq.i::INT - 1), 'text') AS text\n",
    "  FROM raw_posts AS rp, seq_1_to_N AS seq\n",
    "  WHERE seq.i <= JSON_ARRAY_LENGTH(paragraphs)\n",
    "),\n",
    "\n",
    "-- Aggregate the text again\n",
    "aggregated_posts AS (\n",
    "  SELECT\n",
    "    ep.ID2 AS ID3\n",
    "  , ep.first_published_at\n",
    "  , ep.display_title\n",
    "  , LISTAGG(text, ' ') WITHIN GROUP (ORDER BY paragraph) AS text\n",
    "  FROM exploded_posts AS ep\n",
    "  WHERE text <> ''\n",
    "  GROUP BY 1,2,3\n",
    "),\n",
    "\n",
    "-- Select features into a new table\n",
    "text_features AS (\n",
    "SELECT DISTINCT\n",
    "  p3.post_id AS ID4\n",
    ", post_features.ttr_received_total AS total_ttr\n",
    ", post_features.recommends_received_total AS total_reccos\n",
    ", post_features.responses_received_total AS total_responses\n",
    ", post_features.drafting_time AS drafting_time\n",
    ", LISTAGG(tag_post_relations.tag_slug, ',') WITHIN GROUP (ORDER BY tag_post_relations.tag_slug) OVER (PARTITION BY p3.post_id) AS tags\n",
    "FROM posts AS p3\n",
    "JOIN post_features ON  post_features.post_id = p3.post_id\n",
    "JOIN tag_post_relations ON tag_post_relations.post_id = p3.post_id\n",
    "  )\n",
    "\n",
    "-- Aggregate features into final table\n",
    "SELECT ft.ID4 AS post_ID, ft.first_published_at, ft.text, ft.total_ttr, ft.total_reccos, ft.total_responses, ft.drafting_time, ft.tags,\n",
    "  CASE \n",
    "    WHEN (ft.tags LIKE '%politics%') THEN 'Politics'\n",
    "    WHEN (ft.tags LIKE '%life%') THEN 'Life'\n",
    "    WHEN (ft.tags LIKE '%tech%') THEN 'Tech'\n",
    "    WHEN (ft.tags LIKE '%design%') THEN 'Design'\n",
    "    WHEN (ft.tags LIKE '%education%') THEN 'Education'\n",
    "  END AS Genre\n",
    "FROM (aggregated_posts\n",
    "JOIN text_features ON text_features.ID4 = aggregated_posts.ID3) AS ft\n",
    "\n",
    "-- Randomly sample about %30 (75000)\n",
    "-- SET seed to .25 for some reason, SET isn't recognized\n",
    "WHERE first_published_at >= '2015-08-01 00:00:00'\n",
    "ORDER BY random()\n",
    "LIMIT 80000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Occassionally throws \"java.sql.SQLException: [Amazon](500310) Invalid operation: table 1846335 dropped by concurrent transaction;\"\n",
    "# Takes 5.8 min to run for 500 records, 10.6 min for 75000 records\n",
    "\n",
    "dataraw = sqlContext.read.format(\"com.databricks.spark.redshift\")\\\n",
    "  .option(\"url\", redshiftUrl)\\\n",
    "  .option(\"tempdir\", s3Temp)\\\n",
    "  .option(\"query\", query)\\\n",
    "  .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert publish timestamp to date and write as managed table \"genre_NLP_comparison\". \n",
    "\n",
    "from pyspark.sql.functions import to_date  \n",
    "\n",
    "data = dataraw.select('post_ID', to_date('first_published_at').alias('date'), 'text', 'total_ttr', 'total_reccos', 'total_responses', 'drafting_time', 'tags', 'genre')\n",
    "\n",
    "data.write.saveAsTable(\"genre_NLP_comparison\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check that sampling succeeded and the table contains all necessary features\n",
    "all_data_raw = sqlContext.sql(\"SELECT * FROM genre_NLP_comparison\")\n",
    "\n",
    "print all_data_raw.show(5)\n",
    "print all_data_raw.printSchema()\n",
    "print all_data_raw.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_raw.groupBy('genre').count().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Sentiment Score Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exploratory analysis showed a significant dip in sentiment from October 2015 to January 2016 across all genres, though Politics articles seemed to have dipped lower for some reason.  To compare Politics to other genres, we subset our sample twice to separate Politics. \n",
    "\n",
    "# Separate politics articles from rest of corpus\n",
    "Oct_Jan_politics_dip_text = sqlContext.sql(\"SELECT date, post_ID, text from genre_NLP_comparison WHERE date BETWEEN '2015-10-19' AND '2016-01-01' AND genre = 'Politics'\")\n",
    "\n",
    "# Sample articles that are not politics but are from the same time period for comparison\n",
    "Oct_Jan_dip_text = sqlContext.sql(\"SELECT date, genre, post_ID, text from genre_NLP_comparison WHERE date BETWEEN '2015-10-19' AND '2016-01-01' AND genre NOT IN ('Politics')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create user-defined function from VADER module to map compound sentiment score function to the distributed dataframe\n",
    "\n",
    "import pyspark\n",
    "from vaderSentiment.vaderSentiment import sentiment as vaderSentiment\n",
    "\n",
    "def total_sent(x):\n",
    "  y = x.encode('utf-8')\n",
    "  sentan = vaderSentiment(y)\n",
    "  l = sentan['compound']\n",
    "  return l\n",
    "\n",
    "totsent = udf(lambda x: total_sent(x), pyspark.sql.types.FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add 'Total_Sentmt' compound sentiment score as a new column to our dataframe and write this as a new managed table, 'snt_dip'.  This table contains a text sample that excludes politics articles. \n",
    "\n",
    "# Takes about 1 hour to run \n",
    "Oct_Jan_2015_Sent = Oct_Jan_dip_text.withColumn('Total_Sentmt', totsent(Oct_Jan_dip_text.text))\n",
    "Oct_Jan_2015_Sent.write.saveAsTable(\"snt_dip\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a separate table for only politics articles during the dip period\n",
    "snt_dip_p = Oct_Jan_dip_text.withColumn('Total_Sentmt', totsent(Oct_Jan_politics_dip_text.text))\n",
    "snt_dip_p.write.saveAsTable('snt_dip_politics_only', mode='overwrite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This table contains a text sample that includes all five genres across the full time period, August 1 2015 to May 1 2016. \n",
    "\n",
    "# Takes 1 hour 45 min to run\n",
    "five_genre_sent = raw_dat.withColumn('Total_Sent', totsent(raw_dat.text))\n",
    "five_genre_sent.write.saveAsTable(\"five_genre_sentiment\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Test Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Execute SQL to select all posts tagged 'politics', their full text, timestamp, total reading time (ttr), reccomends, responses and tags\n",
    "query = \"\"\"\n",
    " -- Select relevant posts, their text and reading features \n",
    "WITH raw_posts AS (\n",
    "SELECT\n",
    "  posts.post_id AS ID\n",
    ", latest_versions.display_title\n",
    ", TIMESTAMP 'epoch' + posts.first_published_at / 1000 * INTERVAL '1 Second' AS first_published_at\n",
    ", JSON_EXTRACT_PATH_TEXT(latest_versions.content, 'bodyModel', 'paragraphs') AS paragraphs\n",
    "FROM posts\n",
    "-- Full inner join with users, latest_versions and post_features to\n",
    "-- make sure we only consider posts that have all data that we need\n",
    "JOIN users ON users.user_id = posts.creator\n",
    "JOIN latest_versions ON latest_versions.post_id = posts.post_id\n",
    "WHERE\n",
    "  -- Filter that are actually published\n",
    "  posts.first_published_at > 0\n",
    "  AND (posts.visibility = 0 OR posts.visibility = '')\n",
    "  AND posts.deleted_at = 0\n",
    "  AND posts.blacklisted_at = 0\n",
    "  AND users.blacklisted_at = 0\n",
    "  AND latest_versions.is_published\n",
    "  -- Filter posts that are in English\n",
    "  AND posts.detected_language = 'en'\n",
    "  -- Filter posts with tags related to 'politics'\n",
    "  AND posts.post_id IN( \n",
    "    SELECT p2.post_id \n",
    "    FROM posts AS p2 \n",
    "    JOIN tag_post_relations as tog ON p2.post_id = tog.post_id\n",
    "    WHERE tog.tag_slug LIKE '%politics%'\n",
    "    )\n",
    "  -- Remove posts that are responses\n",
    "  AND (posts.in_response_to_post_id = '' OR posts.in_response_to_post_id IS NULL)\n",
    "), \n",
    "-- Generate a series of indices, use LIMIT N to specify the length\n",
    "seq_1_to_N AS (\n",
    "  SELECT ROW_NUMBER() OVER (ORDER BY TRUE) AS i FROM raw_posts\n",
    "  LIMIT 100\n",
    "),\n",
    "-- Explode the paragraphs-array\n",
    "exploded_posts AS (\n",
    "  SELECT\n",
    "    rp.ID AS ID2\n",
    "  , rp.first_published_at\n",
    "  , rp.display_title\n",
    "  , seq.i AS paragraph\n",
    "  , JSON_EXTRACT_PATH_TEXT(JSON_EXTRACT_ARRAY_ELEMENT_TEXT(paragraphs, seq.i::INT - 1), 'text') AS text\n",
    "  FROM raw_posts AS rp, seq_1_to_N AS seq\n",
    "  WHERE seq.i <= JSON_ARRAY_LENGTH(paragraphs)\n",
    "),\n",
    "-- Aggregate the text again\n",
    "aggregated_posts AS (\n",
    "  SELECT\n",
    "    ep.ID2 AS ID3\n",
    "  , ep.first_published_at\n",
    "  , ep.display_title\n",
    "  , LISTAGG(text, ' ') WITHIN GROUP (ORDER BY paragraph) AS text\n",
    "  FROM exploded_posts AS ep\n",
    "  WHERE text <> ''\n",
    "  GROUP BY 1,2,3\n",
    "),\n",
    "text_features AS (\n",
    "SELECT DISTINCT\n",
    "  p3.post_id AS ID4\n",
    ", post_features.ttr_received_total AS total_ttr\n",
    ", post_features.recommends_received_total AS total_reccos\n",
    ", post_features.responses_received_total AS total_responses\n",
    ", LISTAGG(tag_post_relations.tag_slug, ',') WITHIN GROUP (ORDER BY tag_post_relations.tag_slug) OVER (PARTITION BY p3.post_id) AS tags\n",
    "FROM posts AS p3\n",
    "JOIN post_features ON  post_features.post_id = p3.post_id\n",
    "JOIN tag_post_relations ON tag_post_relations.post_id = p3.post_id\n",
    "  )\n",
    "\n",
    "SELECT ft.ID AS Post_ID, ft.first_published_at, ft.text, ft.total_ttr, ft.total_reccos, ft.total_responses\n",
    "FROM (aggregated_posts\n",
    "JOIN text_features ON text_features.ID4 = aggregated_posts.ID3) AS ft\n",
    "ORDER BY first_published_at DESC\n",
    "  , total_ttr DESC \n",
    "  , total_reccos DESC\n",
    "  , total_responses DESC\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_test = sqlContext.read.format(\"com.databricks.spark.redshift\")\\\n",
    "  .option(\"url\", redshiftUrl)\\\n",
    "  .option(\"tempdir\", s3Temp)\\\n",
    "  .option(\"query\", query)\\\n",
    "  .load()\n",
    "  \n",
    "sent_test.write.saveAsTable(\"sent_test\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "\n",
    "# Initial plot from 'sent_test' table containing full sample of 27,000 articles\n",
    "\n",
    "sntmnt_p_mavg <- collect(sql(sqlContext, \"SELECT date, AVG(AVG(Total_Sentmt)) OVER (ORDER BY date ROWS 6 PRECEDING) AS avg_sntmnt FROM sent_test WHERE date >= '2015-08-01' GROUP BY date ORDER BY date ASC\"))\n",
    "\n",
    "library(ggplot2)\n",
    "\n",
    "mn <- min(sntmnt_p_mavg$date) \n",
    "mx <- max(sntmnt_p_mavg$date)\n",
    "\n",
    "p_initial <- ggplot(sntmnt_p_mavg, aes(date, avg_sntmnt)) + \n",
    "  scale_x_date(date_breaks=\"2 week\", limits=c(mn, mx)) +\n",
    "  geom_point(color=\"springgreen4\") + \n",
    "  geom_smooth(span=.25) +\n",
    "#   geom_hline(yintercept=0, color=\"blue\") + \n",
    "#   geom_vline(aes(xintercept=as.numeric(sntmnt_p_mavg$date[105])), color=\"red\", linetype=\"dashed\") +\n",
    "#   geom_text(aes(sntmnt_p_mavg$date[150],.75,label=\"November 13 Paris Attacks\")) +\n",
    "#   geom_vline(aes(xintercept=as.numeric(sntmnt$date[78])), color=\"red\", linetype=\"dashed\") +\n",
    "#   geom_text(aes(sntmnt$date[142],.9,label=\"June 17 Charleston Shooting\")) +\n",
    "  labs(title=\"Weekly Moving Average, Articles Tagged 'Politics' Aug 1 2015 to April 1, 2016\", x=\"Date\", y=\"Sentiment\") +\n",
    "  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n",
    "\n",
    "p_initial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Analytic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "# Examine differences between sentiment scores across all articles, all genres over the full time period. \n",
    "\n",
    "fiveg <- collect(sql(sqlContext, \"SELECT f.post_ID, date, Total_Sent, ln(total_ttr) AS log_ttr, genre, num_words FROM five_genre_sentiment AS f JOIN readability_scores AS r ON f.post_ID = r.post_ID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "# Look at min/max articles for both negative and postive articles for comparison\n",
    "\n",
    "fiveg$valence[fiveg$Total_Sent > 0] <- \"pos\"\n",
    "fiveg$valence[fiveg$Total_Sent < 0] <- \"neg\"\n",
    "\n",
    "fg_pos_articles <- fiveg[fiveg$valence == 'pos',]\n",
    "fg_neg_articles <- fiveg[fiveg$valence == 'neg',]\n",
    "\n",
    "fiveg$genre <- as.factor(fiveg$genre)\n",
    "fiveg$valence <- as.factor(fiveg$valence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "fg_neg_articles <- fg_neg_articles[order(fg_neg_articles$Total_Sent),]\n",
    "fg_neg_articles <- na.omit(fg_neg_articles)\n",
    "head(fg_neg_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "# Negative articles have higher variance than positive articles. \n",
    "library(ggplot2)\n",
    "\n",
    "both <- ggplot(fiveg, aes(x=date, y=Total_Sent, colour = genre)) +\n",
    "  geom_smooth(se=FALSE) + \n",
    "  facet_grid(.~valence)\n",
    "\n",
    "both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r \n",
    "fg_pos_articles <- fg_pos_articles[order(fg_pos_articles$Total_Sent),]\n",
    "fg_pos_articles <- na.omit(fg_pos_articles)\n",
    "\n",
    "head(fg_pos_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "library(ggplot2)\n",
    "\n",
    "pos <- ggplot(fg_pos_articles, aes(x=date, y=Total_Sent, colour = genre)) +\n",
    "  geom_smooth(se=FALSE) + \n",
    "\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "var(na.omit(fg_pos_articles$Total_Sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "var(na.omit(fg_neg_articles$Total_Sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "library(ggplot2)\n",
    "\n",
    "neg <- ggplot(fg_neg_articles, aes(x=date, y=Total_Sent, colour = genre)) +\n",
    "  stat_smooth(se=FALSE)\n",
    "\n",
    "neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "\n",
    "#Articles excluding those tagged politics, published between October 2015 and January 2016\n",
    "\n",
    "sntmnt_no_politics_mavg <- collect(sql(sqlContext, \"SELECT genre, date, AVG(AVG(Total_Sentmt)) OVER (ORDER BY date ROWS 6 PRECEDING) AS avg_sntmnt FROM snt_dip GROUP BY date, genre ORDER BY date ASC\"))\n",
    "\n",
    "# sntmnt_no_politics_mavg$genre <- as.factor(sntmnt_no_politics_mavg$genre) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r \n",
    "\n",
    "#All articles across all five genres published between Oct and Jan\n",
    "\n",
    "sntmnt_all_mavg <- collect(sql(sqlContext, \"SELECT genre, date, AVG(AVG(Total_Sent)) OVER (ORDER BY date ROWS 6 PRECEDING) AS avg_sntmnt FROM five_genre_sentiment WHERE date BETWEEN '2015-10-19' AND '2016-01-01' GROUP BY date, genre ORDER BY date ASC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "\n",
    "#Only articles tagged politics published between Oct and Jan\n",
    "\n",
    "sntmnt_p_mavg <- collect(sql(sqlContext, \"SELECT date, AVG(AVG(Total_Sentmt)) OVER (ORDER BY date ROWS 6 PRECEDING) AS avg_sntmnt FROM snt_dip_politics_only GROUP BY date ORDER BY date ASC\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "library(ggplot2)\n",
    "\n",
    "mn <- min(sntmnt_p_mavg$date) \n",
    "mx <- max(sntmnt_p_mavg$date)\n",
    "\n",
    "p_only <- ggplot(sntmnt_p_mavg, aes(date, avg_sntmnt)) + \n",
    "  scale_x_date(date_breaks=\"2 week\", limits=c(mn, mx)) +\n",
    "  geom_point(color=\"springgreen4\") + \n",
    "  geom_smooth(span=.25) +\n",
    "#   geom_hline(yintercept=0, color=\"blue\") + \n",
    "  geom_vline(aes(xintercept=as.numeric(sntmnt_p_mavg$date[105])), color=\"red\", linetype=\"dashed\") +\n",
    "  geom_text(aes(sntmnt_p_mavg$date[150],.75,label=\"November 13 Paris Attacks\")) +\n",
    "#   geom_vline(aes(xintercept=as.numeric(sntmnt$date[78])), color=\"red\", linetype=\"dashed\") +\n",
    "#   geom_text(aes(sntmnt$date[142],.9,label=\"June 17 Charleston Shooting\")) +\n",
    "  labs(title=\"Weekly Moving Average, Articles Tagged 'Politics'Oct 2015 to Jan, 2016\", x=\"Date\", y=\"Sentiment\") +\n",
    "  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "library(ggplot2)\n",
    "\n",
    "mn <- min(sntmnt_no_politics_mavg$date) \n",
    "mx <- max(sntmnt_no_politics_mavg$date)\n",
    "\n",
    "no_politics <- ggplot(sntmnt_no_politics_mavg, aes(date, avg_sntmnt, color=genre)) + \n",
    "  scale_x_date(date_breaks=\"2 week\", limits=c(mn, mx)) +\n",
    "  geom_point() + \n",
    "  geom_smooth(span=.25, se=FALSE) +\n",
    "#   geom_hline(yintercept=0, color=\"blue\") + \n",
    "#   geom_vline(aes(xintercept=as.numeric(sntmnt_no_politics_mavg$date[105])), color=\"red\", linetype=\"dashed\") +\n",
    "#   geom_text(aes(sntmnt_no_politics_mavg$date[150],.75,label=\"November 13 Paris Attacks\")) +\n",
    "#   geom_vline(aes(xintercept=as.numeric(sntmnt$date[78])), color=\"red\", linetype=\"dashed\") +\n",
    "#   geom_text(aes(sntmnt$date[142],.9,label=\"June 17 Charleston Shooting\")) +\n",
    "  labs(title=\"Weekly Moving Average, Articles Excluding 'Politics' Oct 2015 to Jan 2016\", x=\"Date\", y=\"Sentiment\") +\n",
    "  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "library(ggplot2)\n",
    "# Are we looking at a reaction to a discrete event, or is this merely seasonal depression? Or is this the cumulative effect of several bad things happening in a row? How to weight by TTR? \n",
    "\n",
    "mn <- min(sntmnt_all_mavg$date) \n",
    "mx <- max(sntmnt_all_mavg$date)\n",
    "\n",
    "all_genres <- ggplot(sntmnt_all_mavg, aes(date, avg_sntmnt, color = genre)) + \n",
    "  scale_x_date(date_breaks=\"1 week\", limits=c(mn, mx)) +\n",
    "  geom_point() +  \n",
    "  stat_smooth(span=.25, se=FALSE) +\n",
    "#   geom_hline(yintercept=0, color=\"blue\") + \n",
    "  geom_vline(aes(xintercept=as.numeric(sntmnt_all_mavg$date[126])), color=\"red\", linetype=\"dashed\") +\n",
    "  geom_text(aes(sntmnt_all_mavg$date[210],.85, label=\"November 13 Paris Attacks\"), color=\"black\") +\n",
    "#   geom_vline(aes(xintercept=as.numeric(sntmnt$date[78])), color=\"red\", linetype=\"dashed\") +\n",
    "#   geom_text(aes(sntmnt$date[142],.9,label=\"June 17 Charleston Shooting\")) +\n",
    "  labs(title=\"Weekly Moving Average, All Genres, Oct 19 2015 to Jan 1, 2016\", x=\"Date\", y=\"Sentiment\") +\n",
    "  theme(axis.text.x = element_text(angle = 45, hjust = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "all_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "no_politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "p_only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most commonly occuring quadgrams in articles tagged \"Politics,\" Oct 25, 2015 to Jan 1, 2016\n",
    "\n",
    "|Articles with Positive (>0) Sentiment| Articles with Negative (<0) Sentiment|\n",
    "|-------------------------------------|--------------------------------------|\n",
    "|'hillary', 'clinton', 'bernie', 'sanders'| 'congressional', 'lung', 'cancer', 'caucus'|\n",
    "|'family', 'politico', 'playbook', 'new' | 'conservative', 'americans', 'don't', 'need'|\n",
    "|'new', 'jersey', 'playbook', 'massachusetts'|  'conservative', 'americans', 'don't', 'overthrow'|\n",
    "|'presidential', 'candidate', 'donald', 'trump' |  'conservative', 'americans', 'need', 'overthrow' |\n",
    "|'close', 'digital', 'divide', 'comcast' | 'prisoner', 'disenfranchisement', 'modern', 'racism' |\n",
    "|'complete', 'muslims', 'entering', 'united' | 'lowest', 'pay', 'permitted', 'law' |\n",
    "|'complete', 'shutdown', 'entering', 'united' | 'new', 'york', 'daily', 'news' | \n",
    "|'complete', 'shutdown', 'muslims', 'entering' | 'syrian', 'refugees', 'united', 'states'|\n",
    "|'donald', 'trump', 'ben', 'carson' |  |\n",
    "|'hillary', 'clinton', 'donald', 'trump' |  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment and TTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "\n",
    "#Select TTR and length from sentiment table joined with readability table on post_ID\n",
    "\n",
    "snt <- collect(sql(sqlContext, \"SELECT date, total_ttr, log(total_ttr) AS log_ttr, Total_Sent, num_words, genre AS Genre FROM five_genre_sentiment AS g JOIN readability_scores AS r ON g.post_ID = r.post_ID WHERE date < '2016-05-23'\"))\n",
    "\n",
    "tp_scale <- subset(snt, snt$total_ttr > 0)\n",
    "\n",
    "tp_scale$Genre <- as.factor(tp_scale$Genre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "library(ggplot2)\n",
    "\n",
    "stmt <- ggplot(tp_scale, aes(x = tp_scale$date, y = tp_scale$Total_Sent, color=Genre)) + \n",
    "  scale_y_continuous(breaks=seq(-1,1,.1)) +\n",
    "  geom_point(alpha=.2) +\n",
    "  labs(title=\"Sentiment by Volume, October 2015 to April 2016\", x=\" \", y=\"Normalized VADER Compound Sentiment Score\") +\n",
    "  facet_grid(.~Genre) + \n",
    "  geom_hline(yintercept=0, color=\"red\", linetype=\"dashed\") +\n",
    "  theme(legend.position=\"none\")\n",
    "\n",
    "stmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "library(ggplot2)\n",
    "genre_sent <- ggplot(tp_scale, aes(x = tp_scale$Total_Sent, y = tp_scale$log_ttr, color=Genre)) + \n",
    "#   geom_point(alpha=.2) +\n",
    "  geom_smooth(se=FALSE)  + \n",
    "  scale_y_continuous(breaks=seq(11,15,.25)) +\n",
    "  scale_x_continuous(breaks=seq(-1,1,.1)) +\n",
    "  geom_vline(xintercept=0, color='red', linetype=\"dashed\") +\n",
    "  labs(title=\"Sentiment and Reading Time, October 2015 to April 2016\", x=\"Normalized VADER Compound Sentiment Score\", y=\"Total Time Read (TTR), Natural Log Scale\") +\n",
    "  facet_grid(Genre~.) + \n",
    "  theme(strip.text.y = element_blank())\n",
    "\n",
    "genre_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Sentiment's Effect on TTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "#Looks like this might be a cosine function \n",
    "ttr_sent_neg <- lm(fg_neg_articles$log_ttr~fg_neg_articles$Total_Sent+fg_neg_articles$num_words)\n",
    "print(summary(ttr_sent_neg))\n",
    "\n",
    "ttr_sent_pos <- lm(fg_pos_articles$log_ttr~fg_pos_articles$Total_Sent+fg_pos_articles$num_words)\n",
    "print(summary(ttr_sent_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "#Need to control for num_words\n",
    "sent_mod <- lm(log_ttr~Total_Sent+num_words, data=tp_scale)\n",
    "summary(sent_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%r\n",
    "s_mod <- lm(log_ttr~Total_Sent, data=tp_scale)\n",
    "summary(s_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleaning and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select only post ID and text for cleaning and tokenization\n",
    "raw_text = sqlContext.sql(\"SELECT post_ID, text FROM genre_NLP_comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "general_stopwords = sc.textFile(\"/tmp/stopwords\").collect()\n",
    "\n",
    "mysqlStopwords = list(\"a?s, able, about, above, according, accordingly, across, actually, after, afterwards, again, against, ain?t, all, allow, allows, almost, alone, along, already, also, although, always, am, among, amongst, an, and, another, any, anybody, anyhow, anyone, anything, anyway, anyways, anywhere, apart, appear, appreciate, appropriate, are, aren?t, around, as, aside, ask, asking, associated, at, available, away, awfully, be, became, because, become, becomes, becoming, been, before, beforehand, behind, being, believe, below, beside, besides, best, better, between, beyond, both, brief, but, by, c?mon, c?s, came, can, can?t, cannot, cant, cause, causes, certain, certainly, changes, clearly, co, com, come, comes, concerning, consequently, consider, considering, contain, containing, contains, corresponding, could, couldn?t, course, currently, definitely, described, despite, did, didn?t, different, do, does, doesn?t, doing, don?t, done, down, downwards, during, each, edu, eg, eight, either, else, elsewhere, enough, entirely, especially, et, etc, even, ever, every, everybody, everyone, everything, everywhere, ex, exactly, example, except, far, few, fifth, first, five, followed, following, follows, for, former, formerly, forth, four, from, further, furthermore, get, gets, getting, given, gives, go, goes, going, gone, got, gotten, greetings, had, hadn?t, happens, hardly, has, hasn?t, have, haven?t, having, he, he?s, hello, help, hence, her, here, here?s, hereafter, hereby, herein, hereupon, hers, herself, hi, him, himself, his, hither, hopefully, how, howbeit, however, i?d, i?ll, i?m, i?ve, ie, if, ignored, immediate, in, inasmuch, inc, indeed, indicate, indicated, indicates, inner, insofar, instead, into, inward, is, isn?t, it, it?d, it?ll, it?s, its, itself, just, keep, keeps, kept, know, knows, known, last, lately, later, latter, latterly, least, less, lest, let, let?s, like, liked, likely, little, look, looking, looks, ltd, mainly, many, may, maybe, me, mean, meanwhile, merely, might, more, moreover, most, mostly, much, must, my, myself, name, namely, nd, near, nearly, necessary, need, needs, neither, never, nevertheless, new, next, nine, no, nobody, non, none, noone, nor, normally, not, nothing, novel, now, nowhere, obviously, of, off, often, oh, ok, okay, old, on, once, one, ones, only, onto, or, other, others, otherwise, ought, our, ours, ourselves, out, outside, over, overall, own, particular, particularly, per, perhaps, placed, please, plus, possible, presumably, probably, provides, que, quite, qv, rather, rd, re, really, reasonably, regarding, regardless, regards, relatively, respectively, right, said, same, saw, say, saying, says, second, secondly, see, seeing, seem, seemed, seeming, seems, seen, self, selves, sensible, sent, serious, seriously, seven, several, shall, she, should, shouldn?t, since, six, so, some, somebody, somehow, someone, something, sometime, sometimes, somewhat, somewhere, soon, sorry, specified, specify, specifying, still, sub, such, sup, sure, t?s, take, taken, tell, tends, th, than, thank, thanks, thanx, that, that?s, thats, the, their, theirs, them, themselves, then, thence, there, there?s, thereafter, thereby, therefore, therein, theres, thereupon, these, they, they?d, they?ll, they?re, they?ve, think, third, this, thorough, thoroughly, those, though, three, through, throughout, thru, thus, to, together, too, took, toward, towards, tried, tries, truly, try, trying, twice, two, un, under, unfortunately, unless, unlikely, until, unto, up, upon, us, use, used, useful, uses, using, usually, value, various, very, via, viz, vs, want, wants, was, wasn?t, way, we, we?d, we?ll, we?re, we?ve, welcome, well, went, were, weren?t, what, what?s, whatever, when, whence, whenever, where, where?s, whereafter, whereas, whereby, wherein, whereupon, wherever, whether, which, while, whither, who, who?s, whoever, whole, whom, whose, why, will, willing, wish, with, within, without, won?t, wonder, would, would, wouldn?t, yes, yet, you, you?d, you?ll, you?re, you?ve, your, yours, yourself, yourselves, zero\".split(\",\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "#Filter punctuation and stopwords, then word tokenize each sample to create new column 'word_features' for tf_idf/word2vec preprocessing for LDA topic modeling\n",
    "nltk.download('stopwords')\n",
    "stp = stopwords.words('english')\n",
    "extra = [\"?\", \"n\", '?','\\u2014', '\\u2026', 'orignally', 'published'] + general_stopwords + mysqlStopwords\n",
    "stp.extend(extra)\n",
    "\n",
    "#Remove punctuation, word tokenize and optionally stem tokens \n",
    "def s_filter(x):\n",
    "  nltk.download('punkt')\n",
    "  translate_table = dict((ord(char), None) for char in string.punctuation)\n",
    "  words = nltk.word_tokenize(x.translate(translate_table))\n",
    "  clean_wrds = [i for i in words if not any(b.isdigit() for b in i)]\n",
    "  \n",
    "  a = []\n",
    "  for i in clean_wrds:\n",
    "    if i.lower() not in stp:\n",
    "      a.append(i.lower())\n",
    "  \n",
    "  # stemmer = PorterStemmer()\n",
    "#   s = [stemmer.stem(word) for word in a]\n",
    "#   return s\n",
    "  \n",
    "  return a \n",
    "  \n",
    "s_words = udf(lambda i: s_filter(i), pyspark.sql.types.ArrayType(StringType(), False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write tokens to managed tables for analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only articles tagged politics published between Oct 19, 2015 and Jan 1, 2016\n",
    "politics_tokens = Oct_Jan_politics_dip_text.withColumn('tokens', s_words(Oct_Jan_politics_dip_text.text))\n",
    "politics_tokens.write.saveAsTable(\"politics_tokens\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Articles published between Oct 19 and Jan 1, excluding politics\n",
    "sent_dip_tokens = Oct_Jan_dip_text.withColumn('tokens', s_words(Oct_Jan_dip_text.text))\n",
    "sent_dip_tokens.write.saveAsTable('snt_dip_tokens', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Articles from all 5 genres for full time period, Aug 2015 to May 2016\n",
    "all_genre_tokens = raw_text.withColumn('tokens', s_words(raw_text.text))\n",
    "all_genre_tokens.write.saveAsTable(\"five_genre_tokens\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare negative and positive articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_pos = sqlContext.sql(\"SELECT * from five_genre_sentiment WHERE Total_Sent > 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_neg = sqlContext.sql(\"SELECT * from five_genre_sentiment WHERE Total_Sent < 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_neg_tokens = all_neg.withColumn('tokens', s_words(all_neg.text))\n",
    "all_neg_tokens.write.saveAsTable(\"all_neg_tokens\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_pos_tokens = all_pos.withColumn('tokens', s_words(all_pos.text))\n",
    "all_pos_tokens.write.saveAsTable(\"all_pos_tokens\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens analyzed via LDA in separate notebook:\n",
    "https://dbc-441a36cb-4656.cloud.databricks.com/#notebook/50333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate Part of Speech Tagging to find n-grams that may explain sentiment changes around topics and other named entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Politics articles posted between Oct 25, 2015 and April 1, 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_data_raw = sqlContext.sql(\"SELECT f.post_ID, tokens, date FROM five_genre_tokens f JOIN genre_NLP_comparison g ON f.post_ID = g.post_ID WHERE date BETWEEN '2015-10-25' AND '2016-01-01' AND genre LIKE '%Politics%' ORDER BY date ASC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_data_raw.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_neg = sqlContext.sql(\"SELECT post_ID, tokens, date FROM all_neg_tokens WHERE date BETWEEN '2015-10-25' AND '2016-01-01' AND genre LIKE '%Politics%' ORDER BY date ASC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_neg.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_pos = sqlContext.sql(\"SELECT post_ID, tokens, date FROM all_pos_tokens WHERE date BETWEEN '2015-10-25' AND '2016-01-01' AND genre LIKE '%Politics%' ORDER BY date ASC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_pos.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nltk.download('averaged_perceptron_tagger')\n",
    "tagger = nltk.PerceptronTagger()\n",
    "# tagged =tagger.tag(test.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create separate column with PoS tagging to investigate NA or AN bigram frequencies \n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, StructType, StructField\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "def pos_tagger(x):\n",
    "  nltk.download('averaged_perceptron_tagger')\n",
    "  tagger = nltk.PerceptronTagger()\n",
    "  s = tagger.tag(x)\n",
    "  return s\n",
    "\n",
    "tag_pos = udf(lambda i: pos_tagger(i), ArrayType(StructType([StructField(\"word\", StringType(), False), StructField(\"pos\", StringType(), False)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tags = pos_data_raw.select('post_ID', 'tokens')\n",
    "\n",
    "pos_tagged_tokens_politics = pos_tags.withColumn('pos_tagged_tokens', tag_pos(pos_tags.tokens))\n",
    "# politics_tokens.write.saveAsTable(\"politics_tokens\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Select words and POS tags from RDD\n",
    "testu = pos_tagged_tokens_politics.select('pos_tagged_tokens')\n",
    "POS = testu.flatMap(lambda i: i.pos_tagged_tokens)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Collect POS tagged tokens into a list\n",
    "POS_fin = POS.map(lambda i: (i.word, i.pos)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POS_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Examine articles with negative sentiment\n",
    "neg_tag_tokens = tagged_neg.withColumn('pos_tagged_tokens', tag_pos(tagged_neg.tokens))\n",
    "Neg = neg_tag_tokens.select('pos_tagged_tokens')\n",
    "Neggy = Neg.flatMap(lambda i: i.pos_tagged_tokens)\n",
    "Neg_fin = Neggy.map(lambda i: (i.word, i.pos)).collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Examine articles with positive sentiment\n",
    "\n",
    "pos_tag_tokens = tagged_pos.withColumn('pos_tagged_tokens', tag_pos(tagged_pos.tokens))\n",
    "posi = pos_tag_tokens.select('pos_tagged_tokens')\n",
    "Posit = posi.flatMap(lambda i: i.pos_tagged_tokens)\n",
    "Posi_fin = Posit.map(lambda i: (i.word, i.pos)).collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.metrics.association import QuadgramAssocMeasures\n",
    "\n",
    "quadgram_measures = QuadgramAssocMeasures()\n",
    "\n",
    "finder = QuadgramCollocationFinder.from_words(POS_fin, window_size=5)\n",
    "\n",
    "extra = ['like', 'comment', 'follow', 'allen', 'mikeallen', 'mallenpoliticocom', 'daniel', 'lippman', 'dlippman', 'dlippmanpoliticocom', 'settings', 'httpwwwpoliticocomregistration', 'twitter', 'medium', 'semipartisansamcom', 'originally', 'violently', 'disagree', 'scroll']\n",
    "ignored_words = nltk.corpus.stopwords.words('english') + extra\n",
    "finder.apply_word_filter(lambda (w,t): len(w) < 3 or w.lower() in ignored_words)\n",
    "\n",
    "# finder only excludes patterns rather than selecting them. Need to use chunk module to find descriptive phrases about named entities http://www.nltk.org/api/nltk.chunk.html\n",
    "# finder.apply_ngram_filter(lambda (w1,t1), (w2,t2): t2.startswith('NN') and t1.startswith('JJ'))\n",
    "\n",
    "finder.apply_freq_filter(10)\n",
    "\n",
    "print finder.nbest(quadgram_measures.pmi, 10) \n",
    "print finder.nbest(quadgram_measures.likelihood_ratio, 10) \n",
    "print finder.nbest(quadgram_measures.raw_freq, 10) \n",
    "print finder.nbest(quadgram_measures.chi_sq, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quadgram_measures = QuadgramAssocMeasures()\n",
    "\n",
    "finder = QuadgramCollocationFinder.from_words(Posi_fin, window_size=5)\n",
    "\n",
    "extra = ['like', 'comment', 'follow', 'allen', 'mikeallen', 'mallenpoliticocom', 'daniel', 'lippman', 'dlippman', 'dlippmanpoliticocom', 'settings', 'httpwwwpoliticocomregistration', 'twitter', 'medium', 'semipartisansamcom', 'originally', 'violently', 'disagree', 'scroll']\n",
    "ignored_words = nltk.corpus.stopwords.words('english') + extra\n",
    "finder.apply_word_filter(lambda (w,t): len(w) < 3 or w.lower() in ignored_words)\n",
    "\n",
    "finder.apply_freq_filter(5)\n",
    "\n",
    "# print finder.nbest(quadgram_measures.pmi, 10) \n",
    "print finder.nbest(quadgram_measures.likelihood_ratio, 10) \n",
    "print finder.nbest(quadgram_measures.raw_freq, 10) \n",
    "# print finder.nbest(quadgram_measures.chi_sq, 10)\n",
    "\n",
    "b = []\n",
    "\n",
    "for ((w1,t1), (w2,t2), (w3,t3), (w4,t4)) in finder.nbest(quadgram_measures.raw_freq, 100): \n",
    "  if (t2.startswith('NN') or t3.startswith('NN')) and (t1.startswith('JJ') or t4.startswith('JJ')): \n",
    "      b.append((w1, w2, w3, w4)) \n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quadgram_measures = QuadgramAssocMeasures()\n",
    "\n",
    "finder = QuadgramCollocationFinder.from_words(Neg_fin, window_size=5)\n",
    "\n",
    "extra = ['like', 'comment', 'follow', 'allen', 'mikeallen', 'mallenpoliticocom', 'daniel', 'lippman', 'dlippman', 'dlippmanpoliticocom', 'settings', 'httpwwwpoliticocomregistration', 'twitter', 'medium', 'semipartisansamcom', 'originally', 'violently', 'disagree', 'scroll']\n",
    "ignored_words = nltk.corpus.stopwords.words('english') + extra\n",
    "finder.apply_word_filter(lambda (w,t): len(w) < 3 or w.lower() in ignored_words)\n",
    "\n",
    "finder.apply_freq_filter(5)\n",
    "\n",
    "# print finder.nbest(quadgram_measures.pmi, 10) \n",
    "print finder.nbest(quadgram_measures.likelihood_ratio, 10) \n",
    "print finder.nbest(quadgram_measures.raw_freq, 10) \n",
    "# print finder.nbest(quadgram_measures.chi_sq, 10)\n",
    "\n",
    "b = []\n",
    "\n",
    "for ((w1,t1), (w2,t2), (w3,t3), (w4,t4)) in finder.nbest(quadgram_measures.raw_freq, 100): \n",
    "  if (t2.startswith('NN') or t3.startswith('NN')) and (t1.startswith('JJ') or t4.startswith('JJ')): \n",
    "      b.append((w1, w2, w3, w4)) \n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "\n",
    "# bb = process(POS_fin)\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "finder = BigramCollocationFinder.from_words(POS_fin)\n",
    "\n",
    "ignored_words = nltk.corpus.stopwords.words('english')\n",
    "finder.apply_word_filter(lambda (w,t): len(w) < 3 or w.lower() in ignored_words)\n",
    "\n",
    "# finder.apply_ngram_filter(lambda (w1,t1), (w2,t2): t2.startswith('NN') and t1.startswith('JJ'))\n",
    "\n",
    "finder.apply_freq_filter(10)\n",
    "\n",
    "print finder.nbest(bigram_measures.pmi, 10) \n",
    "print finder.nbest(bigram_measures.likelihood_ratio, 10) \n",
    "print finder.nbest(bigram_measures.raw_freq, 10) \n",
    "print finder.nbest(bigram_measures.chi_sq, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "\n",
    "# bb = process(POS_fin)\n",
    "\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "finder = TrigramCollocationFinder.from_words(POS_fin, window_size=4)\n",
    "\n",
    "extra = ['like', 'comment', 'follow', 'allen', 'mikeallen', 'mallenpoliticocom', 'daniel', 'lippman', 'dlippman', 'dlippmanpoliticocom', 'settings', 'httpwwwpoliticocomregistration', 'twitter', 'medium', 'semipartisansamcom', 'originally']\n",
    "ignored_words = nltk.corpus.stopwords.words('english') + extra\n",
    "finder.apply_word_filter(lambda (w,t): len(w) < 3 or w.lower() in ignored_words)\n",
    "\n",
    "finder.apply_ngram_filter(lambda (w1,t1), (w2,t2), (w3,t3): t2.startswith('NN') and (t1.startswith('JJ') or t3.startswith('JJ')))\n",
    "\n",
    "finder.apply_freq_filter(10)\n",
    "\n",
    "# print finder.nbest(trigram_measures.pmi, 10) \n",
    "print finder.nbest(trigram_measures.likelihood_ratio, 10) \n",
    "print finder.nbest(trigram_measures.raw_freq, 10) \n",
    "# print finder.nbest(trigram_measures.chi_sq, 10) \n",
    "\n",
    "# Appears that the Presidential election and the frontrunner democratic candidates (Hilary, Bernie) dominated discussion, as well as Trump's proposed ban on Muslims entering the U.S., though no specific mention of Trump. Unclear what \"traditional public schools\" might refer to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# About 600 articles tagged \"Politics\" with negative sentiment published between Oct 25, 2015 and Jan 1, 2016\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "finder = TrigramCollocationFinder.from_words(Neg_fin, window_size=4)\n",
    "\n",
    "extra = ['like', 'comment', 'follow', 'allen', 'mikeallen', 'mallenpoliticocom', 'daniel', 'lippman', 'dlippman', 'dlippmanpoliticocom', 'settings', 'httpwwwpoliticocomregistration', 'twitter', 'medium', 'semipartisansamcom', 'originally']\n",
    "ignored_words = nltk.corpus.stopwords.words('english') + extra\n",
    "finder.apply_word_filter(lambda (w,t): len(w) < 3 or w.lower() in ignored_words)\n",
    "\n",
    "# finder.apply_ngram_filter(lambda (w1,t1), (w2,t2), (w3,t3): t2.startswith('NN') and (t1.startswith('JJ') or t3.startswith('JJ')))\n",
    "\n",
    "finder.apply_freq_filter(10)\n",
    "\n",
    "print finder.nbest(trigram_measures.likelihood_ratio, 10) \n",
    "print finder.nbest(trigram_measures.raw_freq, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#About 1300 articles tagged \"Politics\" with positive sentiment\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "finder = TrigramCollocationFinder.from_words(Posi_fin, window_size=4)\n",
    "\n",
    "extra = ['like', 'comment', 'follow', 'allen', 'mikeallen', 'mallenpoliticocom', 'daniel', 'lippman', 'dlippman', 'dlippmanpoliticocom', 'settings', 'httpwwwpoliticocomregistration', 'twitter', 'medium', 'semipartisansamcom', 'originally']\n",
    "ignored_words = nltk.corpus.stopwords.words('english') + extra\n",
    "finder.apply_word_filter(lambda (w,t): len(w) < 3 or w.lower() in ignored_words)\n",
    "\n",
    "# finder.apply_ngram_filter(lambda (w1,t1), (w2,t2), (w3,t3): t2.startswith('NN') and (t1.startswith('JJ') or t3.startswith('JJ')))\n",
    "\n",
    "finder.apply_freq_filter(10)\n",
    "\n",
    "print finder.nbest(trigram_measures.likelihood_ratio, 10) \n",
    "print finder.nbest(trigram_measures.raw_freq, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filtering for a specific noun like 'clinton' doesn't seem to work for some reason. \n",
    "\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "finder = TrigramCollocationFinder.from_words(POS_fin, window_size=4)\n",
    "\n",
    "extra = ['like', 'comment', 'follow', 'allen', 'mikeallen', 'mallenpoliticocom', 'daniel', 'lippman', 'dlippman', 'dlippmanpoliticocom', 'settings', 'httpwwwpoliticocomregistration', 'twitter', 'medium', 'semipartisansamcom', 'originally']\n",
    "ignored_words = nltk.corpus.stopwords.words('english') + extra\n",
    "\n",
    "finder.apply_word_filter(lambda (w,t): len(w) < 3 or w.lower() in ignored_words)\n",
    "\n",
    "finder.apply_freq_filter(5)\n",
    "\n",
    "# finder.apply_ngram_filter(lambda (w1,t1), (w2,t2), (w3,t3): (w2 == 'clinton') and (t1.startswith('JJ') or t3.startswith('JJ')))\n",
    " \n",
    "print finder.nbest(trigram_measures.likelihood_ratio, 10) \n",
    "print finder.nbest(trigram_measures.raw_freq, 10) \n",
    "\n",
    "b = []\n",
    "\n",
    "for ((w1,t1), (w2,t2), (w3,t3)) in finder.nbest(trigram_measures.raw_freq, 100): \n",
    "  if t2.startswith('NN') and (t1.startswith('JJ') or t3.startswith('JJ')): \n",
    "      b.append((w1, w2, w3)) \n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "\n",
    "finder = TrigramCollocationFinder.from_words(POS_fin, window_size=4)\n",
    "\n",
    "extra = ['like', 'comment', 'follow', 'allen', 'mikeallen', 'mallenpoliticocom', 'daniel', 'lippman', 'dlippman', 'dlippmanpoliticocom', 'settings', 'httpwwwpoliticocomregistration', 'twitter', 'medium', 'semipartisansamcom', 'originally']\n",
    "ignored_words = nltk.corpus.stopwords.words('english') + extra\n",
    "\n",
    "finder.apply_word_filter(lambda (w,t): len(w) < 3 or w.lower() in ignored_words)\n",
    "\n",
    "finder.apply_freq_filter(5)\n",
    "\n",
    "b = []\n",
    "\n",
    "for ((w1,t1), (w2,t2), (w3,t3)) in finder.nbest(trigram_measures.raw_freq, 100): \n",
    "  if t2.startswith('NN') and (t1.startswith('JJ') or t3.startswith('JJ')): \n",
    "      b.append((w1, w2, w3)) \n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(sentence):\n",
    "  b = []\n",
    "  for (w1,t1), (w2,t2) in nltk.bigrams(sentence): \n",
    "    if (t1.startswith('JJ') and t2.startswith('NN')): \n",
    "      b.append((w1, w2)) \n",
    "  return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "process(POS_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trump_process(sentence):\n",
    "  for (w1,t1), (w2,t2), (w3,t3) in nltk.trigrams(sentence): # [_three-word]\n",
    "    if (t2 == 'trump') and (t1.startswith('JJ') or (t3.startswith('JJ'))): \n",
    "        print(w1, w2, w3) # [_print-words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trump_process(POS_fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine n-Gram Frequencies to Sense Check LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import *\n",
    "\n",
    "#Examine associted term frequency during 'dip' sentiment period, 17940 total articles across 5 genres \n",
    "tf_data = sqlContext.table('snt_dip_tokens')l\n",
    "tokens = tf_data.select('tokens').rdd.map(lambda j: j.tokens).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_tokens = []\n",
    "for item in tokens:\n",
    "  all_tokens.extend(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# How to set \"adjective noun\" pattern? Need to do this from the same set of tokens as LDA. \n",
    "finder = BigramCollocationFinder.from_words(all_tokens)#, window_size=4)\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(finder.nbest(bigram_measures.likelihood_ratio, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#Create your bigrams\n",
    "bgs = nltk.bigrams(nonum_tokens)\n",
    "\n",
    "#compute frequency distribution for all the bigrams in the text\n",
    "fdist = nltk.FreqDist(bgs)\n",
    "\n",
    "for k,v in fdist.items():\n",
    "    print k,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(finder.nbest(bigram_measures.raw_freq, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(finder.nbest(bigram_measures.pmi, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(finder.nbest(bigram_measures.chi_sq, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(finder.nbest(bigram_measures.student_t, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(finder.ngram_fd.items(), key=lambda t: (-t[1], t[0]))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trifinder = TrigramCollocationFinder.from_words(nonum_tokens)\n",
    "sorted(trifinder.ngram_fd.items(), key=lambda t: (-t[1], t[0]))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
    "sorted(trifinder.nbest(trigram_measures.likelihood_ratio, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdist.pformat(maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.probability import *\n",
    "\n",
    "fdist = FreqDist(w.lower() for w in nonum_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdist['paris']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdist['trump']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdist['clinton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdist.N()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdist.B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdist.freq('paris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdist.freq('trump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdist['terrorist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdist['attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdist['shooting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finder.ngram_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfinished Python LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ag_df = sqlContext.sql(\"SELECT *, cast(ROW_NUMBER() OVER () AS BIGINT) AS id FROM five_genre_tokens\")\n",
    "\n",
    "#  Need to preprocess other dataset, since politics_tokens only has 2121 records in the subsample\n",
    "# p_df = sqlContext.sql(\"SELECT *, cast(ROW_NUMBER() OVER () AS BIGINT) AS id FROM politics_tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "ag_vectorizer = CountVectorizer(inputCol=\"tokens\", outputCol=\"features\").fit(ag_df)\n",
    "all_genre_lda = ag_vectorizer.transform(ag_df)\n",
    "\n",
    "# p_vectorizer = CountVectorizer(inputCol=\"tokens\", outputCol=\"features\").fit(p_df)\n",
    "# politics_lda = p_vectorizer.transform(p_df) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ag_lda_input = all_genre_lda.select(\"id\", \"features\").map(lambda x: [x[1], x[0]])\n",
    "# p_lda_input = politics_lda.select(\"id\", \"features\").map(lambda x: [x[1], x[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "\n",
    "model = LDA.train(ag_lda_input, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Output topics. Each is a distribution over words (matching word count vectors)\n",
    "print(\"Learned topics (as distributions over vocab of \" + str(model.vocabSize()) + \" words):\")\n",
    "topics = model.topicsMatrix()\n",
    "for topic in range(5):\n",
    "    print(\"Topic \" + str(topic) + \":\")\n",
    "    for word in range(0, model.vocabSize()):\n",
    "        print(\" \" + str(topics[word][topic]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = p_df.select(\"tokens\").rdd.map(list)\n",
    "model = Word2Vec().setMinCount(1000).setNumPartitions(20).fit(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synonyms = model.findSynonyms(\"paris\", 40)\n",
    "for word, cosine_distance in synonyms:\n",
    "    print(\"{}: {}\".format(word, cosine_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ag_lda_input.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "\n",
    "# Topic modeling with LDA\n",
    "all_genres_model = LDA.train(ag_lda_input, k=5)\n",
    "politics_model = LDA.train(p_lda_input, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pyspark\n",
    "from pyspark.sql.functions import udf\n",
    "from nltk.data import load\n",
    "from nltk.corpus import stopwords\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from vaderSentiment.vaderSentiment import sentiment as vaderSentiment\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "from textstat.textstat import textstat\n",
    "import string\n",
    "\n",
    "datums = sqlContext.table(\"genre_NLP_comparison\")\n",
    "\n",
    "# Needed to install punkt tokenizer, as it wasn't available immediately from installing nltk. Upon cluster reboot or notebook re-attachment, command will need to be re-run\n",
    "# nltk.download('punkt')\n",
    "# nltk.download(\"stopwords\")\n",
    "tokenizer = load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "#May also be having an issue with NLTK https://github.com/nltk/nltk/issues/1228, so trying vaderSentiment library from PyPi rather than NLTK version\n",
    "# nltk.download('vader_lexicon')\n",
    "# nltk.download('vader_lexicon.txt')\n",
    "# nltk.data.load('vader_sentiment_lexicon.txt')\n",
    "\n",
    "# Define function to count number of sentences per article and return as integer\n",
    "def gustavstokenizer(x):\n",
    "    t = tokenizer.tokenize(x)\n",
    "    return len(t) \n",
    "\n",
    "nsent = udf(lambda i: gustavstokenizer(i), pyspark.sql.types.IntegerType())\n",
    "\n",
    "df = datums.withColumn('num_sent', nsent(data.text))\n",
    "\n",
    "# Define function to count words per article and return as integer\n",
    "_treebank_word_tokenize = TreebankWordTokenizer().tokenize\n",
    "\n",
    "def numwords(x):\n",
    "  z = [token for sent in tokenizer.tokenize(x)\n",
    "            for token in _treebank_word_tokenize(sent)]\n",
    "  return len(z)\n",
    "\n",
    "nwords = udf(lambda i: numwords(i), pyspark.sql.types.IntegerType())\n",
    "\n",
    "dftwo = df.withColumn('num_words', nwords(data.text))\n",
    "\n",
    "# Filter text with fewer than 20 words in order to avoid articles with \"0\" sentences. Readability and Sentiment require dividing by sentence count, so this value must be >0. \n",
    "filtered = dftwo.filter(dftwo.num_sent > 1)\n",
    "\n",
    "# Define function to calculate New Dale-Chall readability score as return as a Double\n",
    "def readingL(j):\n",
    "  l = textstat.dale_chall_readability_score(j)\n",
    "  return l\n",
    "\n",
    "readL = udf(lambda x: readingL(x), pyspark.sql.types.DoubleType())\n",
    "\n",
    "dfthree = filtered.withColumn('Readability', readL(filtered.text))\n",
    "\n",
    "# Text is in ASCII, needs to be Unicode - This may be an error in Vader's source code that uses str() http://stackoverflow.com/questions/9942594/unicodeencodeerror-ascii-codec-cant-encode-character-u-xa0-in-position-20. To correct this, vader was attached directly as a library rather than using the version integrated with NLTK. \n",
    "\n",
    "# Calculate compound sentiment scores \n",
    "def total_sent(x):\n",
    "  y = x.encode('utf-8')\n",
    "  sentan = vaderSentiment(y)\n",
    "  l = sentan['compound']\n",
    "  return l\n",
    "\n",
    "totsent = udf(lambda x: total_sent(x), pyspark.sql.types.FloatType())\n",
    "\n",
    "dffour = dfthree.withColumn('Total_Sentmt', totsent(data.text))\n",
    "\n",
    "# Calculate negative sentiment scores\n",
    "def neg_sent(x):\n",
    "    y = x.encode('utf-8')\n",
    "    sentan = vaderSentiment(y)\n",
    "    l = sentan['neg']\n",
    "    return l\n",
    "\n",
    "negsent = udf(lambda x: neg_sent(x), pyspark.sql.types.FloatType())\n",
    "\n",
    "dffive = dffour.withColumn('Neg_Sentmt', negsent(data.text))\n",
    "\n",
    "# Calculate neutral sentiment\n",
    "def neu_sent(x):\n",
    "    y = x.encode('utf-8')\n",
    "    sentan = vaderSentiment(y)\n",
    "    l = sentan['neu']\n",
    "    return l\n",
    "\n",
    "neusent = udf(lambda x: neu_sent(x), pyspark.sql.types.FloatType())\n",
    "\n",
    "dfsix = dffive.withColumn('Neu_Sentmt', neusent(data.text))\n",
    "\n",
    "# Calculate positive sentiment \n",
    "def pos_sent(x):\n",
    "    y = x.encode('utf-8')\n",
    "    sentan = vaderSentiment(y)\n",
    "    l = sentan['pos']\n",
    "    return l\n",
    "\n",
    "possent = udf(lambda x: pos_sent(x), pyspark.sql.types.FloatType())\n",
    "\n",
    "dfsev = dfsix.withColumn('Pos_Sentmt', possent(data.text))    \n",
    "\n",
    "#Filter punctuation and stopwords, then word tokenize each sample to create new column 'word_features' for tf_idf/word2vec preprocessing for LDA topic modeling\n",
    "stp = set(stopwords.words('english'))\n",
    "\n",
    "def s_filter(x):\n",
    "  nltk.download('punkt')\n",
    "  translate_table = dict((ord(char), None) for char in string.punctuation)\n",
    "  words = nltk.word_tokenize(x.translate(translate_table))  \n",
    "  a = []\n",
    "  for i in words:\n",
    "    if i.lower() not in stp:\n",
    "      a.append(i)\n",
    "      continue \n",
    "  return a\n",
    "\n",
    "s_words = udf(lambda i: s_filter(i), pyspark.sql.types.ArrayType(StringType(), False))\n",
    "\n",
    "dfate = dfsev.withColumn('word_features', s_words(data.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reformat dates into MM/dd/yyyy for plotting. \n",
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "sntmt_plot = dfate.select('post_ID', to_date('first_published_at').alias('date'), 'num_words', 'num_sent', 'Readability', 'Total_Sentmt', 'Neg_Sentmt', 'Neu_Sentmt', 'Pos_Sentmt', 'total_ttr', 'total_reccos', 'total_responses', 'drafting_time', 'tags', 'genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "#Separate word features from other data cols.  Change sentiment to binary classification label. 0 = negative, 1 = positive\n",
    "feats = dfate.select(F.when(dfate.Total_Sentmt > 0, 1).when(dfate.Total_Sentmt < 0, 0).alias('Snt_Valence'), 'word_features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 500 records took about 17.5 min to write\n",
    "feats.write.saveAsTable(\"word_features\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 500 records requires 20 minutes to write. 10,000 records requires more than 3 hours. Got tired of waiting and canceled the job. \n",
    "sntmt_plot.write.saveAsTable(\"sentiment_analysis\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(sntmt_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snt2 = sqlContext.table(\"sentiment_analysis\")\n",
    "snt2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Attempt to write as managed table, throwing an error about write permissions https://github.com/Stratio/Sparta/issues/413, http://stackoverflow.com/questions/31104125/apache-pyspark-lost-executor-failed-to-create-local-dir. \"Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 86300.0 failed 4 times, most recent failure: Lost task 0.3 in stage 86300.0 (TID 55233, ip-10-50-244-34.us-west-2.compute.internal): java.io.IOException: Failed to create local dir in /local_disk0/spark-01ae408b-df5b-4e86-a803-5691d94cfca2/executor-c1760a67-e2e6-450b-80a1-3dfce0fd7eec/blockmgr-c5ff5729-e7f7-4972-9a22-e79719d63372/3b.\"\n",
    "\n",
    "sntmt_plot.write.saveAsTable(\"sentiment_analysis\", mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snt = sqlContext.table(\"sentiment_analysis\")\n",
    "snt.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ft = sqlContext.table(\"word_features\")\n",
    "ft.show(5)\n",
    "print ft.dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print ft.describe()\n",
    "print type(ft)\n",
    "ft.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pre-process with TF_IDF or Word2vec on the 'word_features' column\n",
    "#Word2vec\n",
    "from pyspark.mllib.feature import Word2Vec\n",
    "\n",
    "features = sqlContext.table(\"word_features\")\n",
    "           \n",
    "ft = features.rdd.map(list)\n",
    "\n",
    "# select('word_features').\n",
    "\n",
    "# fg = ft.rdd.map(list)\n",
    "wtv_model = Word2Vec().setMinCount(1).setNumPartitions(5).fit(ft)\n",
    "# word2vec = Word2Vec()\n",
    "# model = word2vec.fit(ft)\n",
    "# model = Word2Vec().setVectorSize(10).setSeed(42).fit(ft)\n",
    "\n",
    "wrd_vecs = wtv_model.getVectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(wrd_vecs)\n",
    "wrd_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synonyms = wtv_model.findSynonyms('crowd', 1)\n",
    "\n",
    "for word, cosine_distance in synonyms:\n",
    "    print(\"{}: {}\".format(word, cosine_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print type(ft)\n",
    "print ft.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TF_IDF\n",
    "from pyspark import SparkContext\n",
    "# from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# sentenceData = sqlContext.createDataFrame([\n",
    "#   (0, \"Hi I heard about Spark\"),\n",
    "#   (0, \"I wish Java could use case classes\"),\n",
    "#   (1, \"Logistic regression models are neat\")\n",
    "# ], [\"label\", \"sentence\"])\n",
    "# tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "# wordsData = tokenizer.transform(sentenceData)\n",
    "# hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "# featurizedData = hashingTF.transform(wordsData)\n",
    "\n",
    "\n",
    "# fields = [StructField('Snt_Valence', IntegerType(), False), StructField('word_features', ArrayType(StringType()), False)]\n",
    "# schema = StructType(fields)\n",
    "# values = sqlContext.table(\"word_features\")\n",
    "\n",
    "# features = sqlContext.createDataFrame(values, schema)\n",
    "\n",
    "features = sqlContext.table(\"word_features\")\n",
    "\n",
    "vectorizer = CountVectorizer(inputCol=\"word_features\", outputCol=\"vec_features\").fit(features)\n",
    "# vectorizer.vocabulary\n",
    "\n",
    "lda = vectorizer.transform(features)\n",
    "fe = lda.select(\"word_features\", \"vec_features\").rdd\n",
    "lda_feats = fe.map(lambda row: row.asDict())\n",
    "\n",
    "# .select(\"vec_features\").rdd\n",
    "\n",
    "# Have not been able to get SparkMLib's Hashing_TF to produce usable output. \n",
    "# ft = features.rdd.map(list)\n",
    "# hashingTF = HashingTF()\n",
    "\n",
    "# tf = hashingTF.transform(features)\n",
    "\n",
    "#  key, value structure of\n",
    "# document_id, [token_ids]\n",
    "\n",
    "# The second is an inverted index like\n",
    "# token_id, [document_ids]\n",
    "# I'll call those corpus and inv_index respectively.\n",
    "\n",
    "# from collections import Counter\n",
    "# def wc_per_row(row):\n",
    "#     cnt = Counter()\n",
    "#     for word in row:\n",
    "#         cnt[word] += 1\n",
    "#     return cnt.items() \n",
    "\n",
    "# tf = features.map(lambda (x, y): (x, wc_per_row(y)))\n",
    "\n",
    "# ... continue from the previous example\n",
    "# idf = IDF()\n",
    "# idfmodel = idf.fit(tf)\n",
    "\n",
    "# tfidf = idfmodel.transform(tf)\n",
    "\n",
    "# indexer = StringIndexer(inputCol='post_ID',outputCol='KeyIndex')\n",
    "# indexed_data = indexer.fit(tfidf).transform(tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(lda_feats)\n",
    "lda_feats.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Topic modeling with LDA\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "# from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "# Parse data by line to convert to vectors\n",
    "# parsedData = tf.map(lambda line: Vectors.dense([float(x) for x in line]))\n",
    "\n",
    "# Index documents with unique IDs\n",
    "# corpus = parsedData.zipWithIndex().map(lambda x: [x[1], x[0]]).cache()\n",
    "\n",
    "# Cluster the documents into three topics using LDA\n",
    "# rdd = sc.parallelize(tf)\n",
    "# k = 5 # number of clusters\n",
    "model = LDA.train(lda_feats, k=5)\n",
    "\n",
    "# # Output topics. Each is a distribution over words (matching word count vectors)\n",
    "# print(\"Learned topics (as distributions over vocab of \" + str(ldaModel.vocabSize()) + \" words):\")\n",
    "# topics = ldaModel.topicsMatrix()\n",
    "# for topic in range(5):\n",
    "#     print(\"Topic \" + str(topic) + \":\")\n",
    "#     for word in range(0, ldaModel.vocabSize()):\n",
    "#         print(\" \" + str(topics[word][topic]))\n",
    "\t\t\n",
    "# Save and load model\n",
    "# model.save(sc, \"myModelPath\")\n",
    "# sameModel = LDAModel.load(sc, \"myModelPath\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": "Sentiment_final_analysis_May_2016",
  "notebookId": 41703
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
